{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "7pieevqllh6iwjkg6j2z",
   "authorId": "3739233679026",
   "authorName": "PKOTA",
   "authorEmail": "pkota@ncl.com",
   "sessionId": "6943a798-46f0-4381-878b-61886d1406ef",
   "lastEditTime": 1767598978602
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "Importing_Libraries",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "import snowflake.snowpark as snowpark\nfrom snowflake.snowpark import functions as F\nfrom snowflake.snowpark.window import Window\nfrom snowflake.snowpark import types as T\nfrom datetime import datetime \n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "Importing_Required_Data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "# Reading declaring master file and account rollup file\n\nmaster_file = session.table(\"Vessops_D.L20_BDV.SAT_VFM_NCL_MASTER_DATA\").with_column(\"SAIL_DAT\", F.to_date(F.col(\"SAIL_DAT\"))).drop(\"MD5_HUB_VOYAGE\",\"HASH_DIFF\",\"LDTS\",\"RCSR\",\"LAST_MODIFIED_BY\")\n\nmaster_file=master_file.with_column('STRADDLE_PAX_PD', F.col('PAX_DAYS')/F.col('SAIL_DAY_QTY'))\\\n                        .with_column('STRADDLE_PAX', F.col('STRADDLE_PAX_PD')*F.col('CONV_SAIL_DAY_QTY'))\n\n\nmapping = session.table(\"VESSOPS_D.L10_RDV.VFM_NCLH_ACCOUNT_ROLLUP_MAPPING\").select(\"ACCOUNT_NUMBER\",\"LEVEL_1\",\"LEVEL_2\",\"LEVEL_3\",\"LEVEL_4\")\n\n\n# SIXTH MAN MAPPING FILE\nSIX_MAP = session.table(\"VESSOPS_D.L10_RDV.VFM_NCL_SIXTHMAN_MAPPING\").select(F.col(\"VOYAGE_ID\").alias(\"SIXTHMAN_VOYAGE\"), F.col(\"NCL_ID\").alias(\"TRADITIONAL_VOYAGE_ID\"))\n\n\nvalid_op_units = [\n    'NCL Pride of America', 'NCL Bliss', 'NCL Breakaway', 'NCL Dawn', 'NCL Encore', 'NCL Epic', 'NCL Escape', \n    'NCL Gem', 'NCL Getaway', 'NCL Jade', 'NCL Joy', 'NCL Jewel', 'NCL Prima', 'NCL Pearl', 'NCL Sky', \n    'NCL Spirit', 'NCL Star', 'NCL Sun', 'NCL Viva', 'Common Shipside', 'Common Shoreside', 'NCL Aqua'\n]\nreplacement_map = F.create_map(\n    F.lit(\"SPR240607\"), F.lit(\"SPR240605\"), F.lit(\"SPR240610\"), F.lit(\"SPR240605\"),\n    F.lit(\"SPR240614\"), F.lit(\"SPR240605\"), F.lit(\"SPR240618\"), F.lit(\"SPR240605\"),\n    F.lit(\"SPR240621\"), F.lit(\"SPR240605\"), F.lit(\"SPR240623\"), F.lit(\"SPR240605\"),\n    F.lit(\"SPR240628\"), F.lit(\"SPR240605\"), F.lit(\"SPR240630\"), F.lit(\"SPR240605\"),\n    F.lit(\"SPR240703\"), F.lit(\"SPR240701\"), F.lit(\"SPR240707\"), F.lit(\"SPR240701\"),\n    F.lit(\"SPR240710\"), F.lit(\"SPR240701\"), F.lit(\"SPR240713\"), F.lit(\"SPR240701\"),\n    F.lit(\"SPR240717\"), F.lit(\"SPR240701\"), F.lit(\"SPR240721\"), F.lit(\"SPR240701\"),\n    F.lit(\"SPR240722\"), F.lit(\"SPR240701\"), F.lit(\"SPR240724\"), F.lit(\"SPR240701\"),\n    F.lit(\"SPR240726\"), F.lit(\"SPR240701\"), F.lit(\"SPR240727\"), F.lit(\"SPR240701\"),\n    F.lit(\"SPR240730\"), F.lit(\"SPR240701\"), F.lit(\"SPR240731\"), F.lit(\"SPR240701\"),\n    F.lit(\"SPR240804\"), F.lit(\"SPR240801\"), F.lit(\"SPR240809\"), F.lit(\"SPR240801\"),\n    F.lit(\"SPR240811\"), F.lit(\"SPR240801\"), F.lit(\"SPR240814\"), F.lit(\"SPR240801\"),\n    F.lit(\"SPR240818\"), F.lit(\"SPR240801\"), F.lit(\"SPR240821\"), F.lit(\"SPR240801\"),\n    F.lit(\"SPR240825\"), F.lit(\"SPR240801\"), F.lit(\"SPR240830\"), F.lit(\"SPR240801\"),\n    F.lit(\"SPR240906\"), F.lit(\"SPR240901\"), F.lit(\"SPR240908\"), F.lit(\"SPR240901\"),\n    F.lit(\"SPR240911\"), F.lit(\"SPR240901\"), F.lit(\"SPR240914\"), F.lit(\"SPR240901\"),\n    F.lit(\"SPR240917\"), F.lit(\"SPR240901\"), F.lit(\"SPR240920\"), F.lit(\"SPR240901\")\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ba18ebd5-d0b2-4bbb-852d-b3cfa774adf4",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "master_file.count()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "32179760-3e98-4c3c-b6a3-ec6a47f36631",
   "metadata": {
    "language": "python",
    "name": "NTR_Complete_Code",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# --- Configuration for this specific script ---\nPEOPLESOFT_TABLE = \"VESSOPS_D.L00_STG.NCL_VFM_NTR\"\n\n\ndf_raw = session.table(PEOPLESOFT_TABLE).select(\"FISCAL_YEAR_NUMBER\",\"ACCOUNTING_PERIOD\",\"BUSINESS_UNIT_COMBINED_DESCRIPTION\",\"OPERATING_UNIT_DESCRIPTION\",\n                                                \"SHIP_CD\",\"M0_M1\",\"ACCOUNT\",\"JOURNAL_MONETARY_AMOUNT_ADJ\",\"VOYAGE_ID\")\n\n# # --- Step 3: Initial Cleaning and Filtering of PeopleSoft Data ---\n# print(\"Step 3: Cleaning PeopleSoft data...\")\n\ndf_cleaned = df_raw.filter(~((F.col(\"OPERATING_UNIT_DESCRIPTION\")=='NCL Pride of America') &(F.col(\"BUSINESS_UNIT_COMBINED_DESCRIPTION\")=='NCL00-Norwegian Cruise Line') ))\\\n                   .with_column(\"VOYAGE_ID\",F.coalesce(F.col(\"VOYAGE_ID\"), F.lit(\"No Voyage Cd\")))\\\n                   .with_column(\"VOYAGE_ID\", F.coalesce(F.get(replacement_map, F.col(\"VOYAGE_ID\")), F.col(\"VOYAGE_ID\")))\\\n                   .rename(F.col(\"BUSINESS_UNIT_COMBINED_DESCRIPTION\"), \"BUSINESS_UNIT_DESCRIPTION\")\n\ndf_grouped = df_cleaned.group_by(\"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\", \"ACCOUNT\", \"SHIP_CD\", \"BUSINESS_UNIT_DESCRIPTION\", \"OPERATING_UNIT_DESCRIPTION\",\"VOYAGE_ID\",\"M0_M1\") \\\n                         .agg(F.sum(\"JOURNAL_MONETARY_AMOUNT_ADJ\").alias(\"JOURNAL_MONETARY_AMOUNT_ADJ\"))\\\n\ndf_charter = df_grouped.filter(F.col(\"BUSINESS_UNIT_DESCRIPTION\").in_('SIX00-Sixthman Ltd.','EL013-NCL BERMUDA JURISDICTION ELIM','EL004-Compass & Sweden Elimination')|( F.col(\"VOYAGE_ID\").startswith(\"SM\") | F.col(\"VOYAGE_ID\").startswith(\"SX\")))\n\ndf_inter1 = df_grouped.filter(\n                                ~((F.col(\"BUSINESS_UNIT_DESCRIPTION\").in_('SIX00-Sixthman Ltd.', 'EL013-NCL BERMUDA JURISDICTION ELIM','EL004-Compass & Sweden Elimination') |\n                                    (F.col(\"VOYAGE_ID\").startswith(\"SM\") | F.col(\"VOYAGE_ID\").startswith(\"SX\")))\n                                   ))\n\ndf_norm=df_inter1.filter(~(F.col(\"OPERATING_UNIT_DESCRIPTION\").in_('Common Shoreside','Common Shipside')))\n\ndf_com=df_inter1.filter(F.col(\"OPERATING_UNIT_DESCRIPTION\").in_('Common Shoreside','Common Shipside'))\n\n\n\ndf_charter_mapped= df_charter.join(SIX_MAP, df_charter[\"VOYAGE_ID\"] == SIX_MAP[\"SIXTHMAN_VOYAGE\"], \"left\")\ndf_charter_map=df_charter_mapped.join(master_file.drop(\"SHIP_CD\"), F.col(\"TRADITIONAL_VOYAGE_ID\") == master_file[\"MXP_VOYAGE_CD\"], \"left\")\n\n\ndf_charter2 = df_charter_map.with_column(\"SHIP_CD\",F.when((F.col(\"TRADITIONAL_VOYAGE_ID\").is_not_null()) & \n                                                        (F.length(F.col(\"TRADITIONAL_VOYAGE_ID\")) <= 9),\n                                                        F.substring(F.col(\"TRADITIONAL_VOYAGE_ID\"), 1, 3)\n                            ).otherwise(F.lit(\"Unknown\")))\n\n\ndf_charter2 = df_charter2.with_column(\"TOTAL_PAX_DAYS\", F.sum(\"STRADDLE_PAX\").over(Window.partition_by(\"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\", \"BUSINESS_UNIT_DESCRIPTION\",\"OPERATING_UNIT_DESCRIPTION\", \"VOYAGE_ID\", \"ACCOUNT\")))\\\n                         .with_column(\"PAX_WEIGHTAGE\", F.iff(F.col(\"TOTAL_PAX_DAYS\") == 0, 0, F.col(\"STRADDLE_PAX\") / F.col(\"TOTAL_PAX_DAYS\")))\n\nupdated_amount_col = (\n    F.when((F.col('STRADDLE_FLAG') == 'straddle') &\n            F.col('SAIL_DAY_QTY') > 0,\n            (F.col('JOURNAL_MONETARY_AMOUNT_ADJ') / F.col('SAIL_DAY_QTY')) * F.col('CONV_SAIL_DAY_QTY')\n        ).otherwise(F.lit(0))\n    .when(       \n        (F.col('STRADDLE_FLAG') == 'straddle') &\n        (F.col('MXP_VOYAGE_CD').is_null() | (F.col('MXP_VOYAGE_CD') == 0)),F.lit(0))\n    .otherwise(F.col('JOURNAL_MONETARY_AMOUNT_ADJ')))\n\ndf_charter2 = df_charter2.with_column('JOURNAL_MONETARY_AMOUNT_ADJ',updated_amount_col)\n\n\n# Common shipside & shoreside treatment\n\ndf_no_voyage = df_com.filter(F.col(\"VOYAGE_ID\") == 'No Voyage Cd')\ndf_with_voyage = df_com.filter(F.col(\"VOYAGE_ID\") != 'No Voyage Cd')\n\ndf_no_voyage_merged = df_no_voyage.join(master_file.drop(\"SHIP_CD\"),\n                                        (df_no_voyage[\"FISCAL_YEAR_NUMBER\"] == master_file[\"CONV_SAIL_YEAR\"]) &\n                                           ( df_no_voyage[\"ACCOUNTING_PERIOD\"] == master_file[\"CONV_SAIL_MONTH\"]),\n                                        how=\"left\")\n\ndf_with_voyage_merged = df_with_voyage.join(master_file.drop(\"SHIP_CD\"),\n                                                (df_with_voyage[\"FISCAL_YEAR_NUMBER\"] == master_file[\"CONV_SAIL_YEAR\"]) &\n                                                    (df_with_voyage[\"ACCOUNTING_PERIOD\"] == master_file[\"CONV_SAIL_MONTH\"]) &\n                                                    (df_with_voyage[\"VOYAGE_ID\"] == master_file[\"MXP_VOYAGE_CD\"]),\n                                                how=\"left\")\n\n# Define the \"window\" or group for our calculation (each year and month).\nwindow_spec = Window.partition_by(\"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\")\n\n#  Use the window function to count non-'SX' voyages per group\n# The 'count_non_sx' column is temporary.\ndf_with_count = df_no_voyage_merged.with_column(\"count_non_sx\",\n                                    F.sum(F.when(F.upper(F.col(\"BFS_CHARTER_CD\")) != 'SX',\n                                                 F.lit(1)).otherwise(F.lit(0))).over(window_spec))\n\n# 4. Filter the DataFrame\ndf_no_voyage_merged = df_with_count.filter((F.col(\"count_non_sx\") > 0) | (F.upper(F.col(\"BFS_CHARTER_CD\")) != 'SX'))\\\n                                   .drop(\"count_non_sx\")\n\n\n# df_com1=df_no_voyage_merged.union_all(df_with_voyage_merged)\n\n# # ALLOCATED_AMOUNT tenporary column\n\n# df_com1=df_com1.with_column(\"TOTAL_PAX_DAYS\", F.sum(\"STRADDLE_PAX\").over(Window.partition_by(\"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\", \"BUSINESS_UNIT_DESCRIPTION\",\"OPERATING_UNIT_DESCRIPTION\", \"VOYAGE_ID\", \"ACCOUNT\")))\\\n#                .with_column(\"PAX_WEIGHTAGE\", F.iff(F.col(\"TOTAL_PAX_DAYS\") == 0, 0, F.col(\"STRADDLE_PAX\") / F.col(\"TOTAL_PAX_DAYS\")))\\\n#                .with_column(\"ALLOCATED_AMOUNT\", F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\") * F.col(\"PAX_WEIGHTAGE\"))\\\n#                .with_column(\"ALLOCATED_AMOUNT\",\n#                             F.when((F.col(\"STRADDLE_FLAG\") == 'straddle') & F.col(\"ALLOCATED_AMOUNT\").is_null(),\n#                                     F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\") / 2\n#                             ).otherwise(F.coalesce(F.col(\"ALLOCATED_AMOUNT\"), F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\"))))\\\n#                .with_column(\"JOURNAL_MONETARY_AMOUNT_ADJ\", F.col(\"ALLOCATED_AMOUNT\"))\\\n#                .drop(\"ALLOCATED_AMOUNT\")\n\n\n# # 2. Chain all operations together for efficiency\n# df_com1 = df_com1.with_column(\"VOYAGE_ID\",F.when(F.col(\"VOYAGE_ID\") == 'No Voyage Cd', F.col(\"MXP_VOYAGE_CD\"))\n#                  .otherwise(F.col(\"VOYAGE_ID\")))\\\n#                 .with_column(\"SHIP_CD\",F.substring(F.col(\"VOYAGE_ID\"), 1, 3))\\\n#                 .with_column(\"STRADDLE_OCCURRENCE\",F.row_number()\n#                                                     .over(Window.partition_by(\"SHIP_CD\", \"BUSINESS_UNIT_DESCRIPTION\", \"OPERATING_UNIT_DESCRIPTION\",\n#                                                                                 \"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\", \"VOYAGE_ID\", \"ACCOUNT\",\n#                                                                                 \"STRADDLE_FLAG\", \"VOYAGE_CD\"\n#                                                                             ).order_by(F.col(\"SAIL_DAT\"))))\n\n\n\n\n# # # Define the conditions for the initial buckets ---\n# # condition1 = (F.col(\"ACCOUNT\") == '40013-Cruise Revenue Promo Packages') & (~F.col(\"BFS_CHARTER_CD\").isin('DC', 'SX')) &\\\n# #                     (~F.col(\"VOYAGE_ID\").startswith('SM')) & (~F.col(\"VOYAGE_ID\").startswith('SX'))\n\n# # condition2 = (F.col(\"VOYAGE_ID\") == 'No Voyage Cd') & (F.col(\"MXP_VOYAGE_CD\").is_null()) & (F.col(\"ACCOUNT\") != '40013-Cruise Revenue Promo Packages') &\\\n# #                     (~F.col(\"BFS_CHARTER_CD\").isin('DC', 'SX')) & (~F.col(\"VOYAGE_ID\").startswith('SM')) & (~F.col(\"VOYAGE_ID\").startswith('SX'))\n\n# # condition3 = (F.col(\"STRADDLE_FLAG\") == 'Non-straddle') & (F.col(\"ACCOUNTING_PERIOD\") == F.col(\"CONV_SAIL_MONTH\")) & (F.col(\"FISCAL_YEAR_NUMBER\") == F.col(\"CONV_SAIL_YEAR\")) &\\\n# #                     (F.col(\"ACCOUNT\") != '40013-Cruise Revenue Promo Packages') & (~F.col(\"BFS_CHARTER_CD\").isin('DC', 'SX')) & (~F.col(\"VOYAGE_ID\").startswith('SM')) &\\\n# #                     (~F.col(\"VOYAGE_ID\").startswith('SX'))\n\n# # condition4 = (F.col(\"STRADDLE_FLAG\") == 'straddle') & (F.col(\"ACCOUNTING_PERIOD\") == F.col(\"CONV_SAIL_MONTH\")) &\\\n# #                     (F.col(\"FISCAL_YEAR_NUMBER\") == F.col(\"CONV_SAIL_YEAR\")) & (F.col(\"ACCOUNT\") != '40013-Cruise Revenue Promo Packages') & \\\n# #                     (~F.col(\"BFS_CHARTER_CD\").isin(['DC', 'SX'])) & (~F.col(\"VOYAGE_ID\").startswith('SM')) & (~F.col(\"VOYAGE_ID\").startswith('SX'))\n\n\n# # # Apply the initial bucketing ---\n# # df_com2 = df_com1.with_column(\n# #                     \"VOYAGEBUCKET_TEMP\",\n# #                     F.when(condition1, 'Bucket 1')\n# #                      .when(condition2, 'Bucket 2')\n# #                      .when(condition3, 'Bucket 3')\n# #                      .when(condition4, 'Bucket 4')\n# #                      .otherwise(F.lit(None)))\n\n\n# # df_com2 = df_com2.with_column(\"HAS_BUCKET_IN_GROUP\",\n# #                           F.max(F.when(F.col(\"VOYAGEBUCKET_TEMP\").is_not_null(), 1)\n# #                           .otherwise(0)).over(Window.partition_by('VOYAGE_ID', 'SHIP_CD', 'ACCOUNTING_PERIOD', 'FISCAL_YEAR_NUMBER')))\n\n# # # Apply the final \"Bucket 5\" logic\n# # df_com2 = df_com2.with_column(\"VOYAGEBUCKET\",\n# #                         F.when(F.col(\"VOYAGEBUCKET_TEMP\").is_not_null(), F.col(\"VOYAGEBUCKET_TEMP\"))\n# #                          .when(\n# #                             (F.col(\"VOYAGEBUCKET_TEMP\").is_null()) &\n# #                             (F.col(\"HAS_BUCKET_IN_GROUP\") == 0) &\n# #                             (F.col(\"STRADDLE_OCCURRENCE\") != 2),\n# #                             'Bucket 5'\n# #                          ).otherwise(F.lit(None)))\\\n# #                 .drop(\"VOYAGEBUCKET_TEMP\", \"HAS_BUCKET_IN_GROUP\") \\\n# #                 .with_column(\"VOYAGEBUCKET\",F.coalesce(F.col(\"VOYAGEBUCKET\"), F.lit(\"Bucket 5\")))\n                \n\n# # # Step 2: Aggregate for BUCKET_5\n# # group_keys = [\"SHIP_CD\", \"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\",\n# #     \"BUSINESS_UNIT_DESCRIPTION\", \"OPERATING_UNIT_DESCRIPTION\"]\n\n# # buckets_to_distribute = df_com2.filter(F.col(\"VOYAGEBUCKET\") == \"Bucket 5\")\n# # sums = (buckets_to_distribute.group_by(*group_keys).agg(F.sum(\"JOURNAL_MONETARY_AMOUNT_ADJ\").alias(\"NONPERIODAMOUNT_TO_DISTRIBUTE\")))\n\n\n# # # Step 3: Compute presence flags \n# # pax_group = (df_com2    .group_by(*group_keys, \"VOYAGEBUCKET\")\n# #     .agg(F.sum(\"PAX_DAYS\").alias(\"PAX_SUM\"))\n# # )\n# # bucket3_flag = (\n# #     pax_group\n# #     .filter(F.col(\"VOYAGEBUCKET\") == \"Bucket 3\")\n# #     .with_column(\"BUCKET_3_EXISTS\", F.lit(True))\n# #     .select(*group_keys, \"BUCKET_3_EXISTS\")\n# # )\n# # bucket4_flag = (pax_group\n# #     .filter(F.col(\"VOYAGEBUCKET\") == \"Bucket 4\")\n# #     .with_column(\"BUCKET_4_EXISTS\", F.lit(True))\n# #     .select(*group_keys, \"BUCKET_4_EXISTS\")\n# # )\n# # flags_base = pax_group.select(*group_keys).distinct()\n# # bucket_presence = (\n# #     flags_base\n# #     .join(bucket3_flag, group_keys, \"left\")\n# #     .join(bucket4_flag, group_keys, \"left\")\n# #     .with_column(\"BUCKET_3_EXISTS\", F.coalesce(F.col(\"BUCKET_3_EXISTS\"), F.lit(False)))\n# #     .with_column(\"BUCKET_4_EXISTS\", F.coalesce(F.col(\"BUCKET_4_EXISTS\"), F.lit(False)))\n# # )\n\n# # # Step 4: Merge sums with flags\n# # sumscount = sums.join(bucket_presence, group_keys)\n\n# # # Step 5: Conditional allocation\n# # alloc_base = sumscount.join(df_com2, group_keys)\n# # alloc_base = alloc_base.with_column(\n# #     \"ELIGIBLE_BUCKET\",\n# #     F.when(\n# #         (F.col(\"BUCKET_3_EXISTS\") & F.col(\"BUCKET_4_EXISTS\")) &\n# #         ((F.col(\"VOYAGEBUCKET\") == \"Bucket 3\") | (F.col(\"VOYAGEBUCKET\") == \"Bucket 4\")), F.lit(True)\n# #     ).when(\n# #         F.col(\"BUCKET_3_EXISTS\") & (F.col(\"VOYAGEBUCKET\") == \"Bucket 3\"), F.lit(True)\n# #     ).when(\n# #         F.col(\"BUCKET_4_EXISTS\") & (F.col(\"VOYAGEBUCKET\") == \"Bucket 4\"), F.lit(True)\n# #     ).when(\n# #         ~F.col(\"BUCKET_3_EXISTS\") & ~F.col(\"BUCKET_4_EXISTS\") & (F.col(\"VOYAGEBUCKET\") == \"Bucket Charter\"), F.lit(True)\n# #     ).otherwise(F.lit(False))\n# # )\n# # filtered_alloc = alloc_base.filter(F.col(\"ELIGIBLE_BUCKET\"))\n# # window_spec = Window.partition_by(*group_keys)\n\n# # nonperiodresults =filtered_alloc.with_column(\"TOTAL_STRADDLE_PAX\", F.sum(\"STRADDLE_PAX\").over(window_spec))\\\n# #                                 .with_column(\"NONPERIODDISTRIBUTED_AMOUNT\",F.when(F.col(\"TOTAL_STRADDLE_PAX\") > 0,\n# #                                                  F.col(\"STRADDLE_PAX\") / F.col(\"TOTAL_STRADDLE_PAX\") * F.col(\"NONPERIODAMOUNT_TO_DISTRIBUTE\")\n# #                                                 ).otherwise(F.lit(0))).filter(F.col(\"NONPERIODDISTRIBUTED_AMOUNT\") != 0)\n\n# # join_key_columns = [\"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\", \"BUSINESS_UNIT_DESCRIPTION\",\n# #     \"OPERATING_UNIT_DESCRIPTION\", \"SHIP_CD\", \"M0_M1\", \"VOYAGE_ID\",\"ACCOUNT\",\"VOYAGE_CD\",\n# #     \"STRADDLE_FLAG\", \"CONV_SAIL_DAT\", \"CONV_RETURN_DAT\",\"CONV_SAIL_DAY_QTY\", \"CONV_SAIL_MONTH\", \"CONV_SAIL_YEAR\", \"STRADDLE_PAX_PD\",\n# #     \"STRADDLE_OCCURRENCE\", \"VOYAGEBUCKET\"]\n\n# # # 2. Select the required columns from the 'nonperiodresults' DataFrame.\n# # nonperiodresults1 = nonperiodresults.select(*join_key_columns,\"NONPERIODDISTRIBUTED_AMOUNT\")\n\n\n# # df_com3 = df_com2.join(nonperiodresults1,on=join_key_columns,how='left')\n\n\n# # df_com3 = df_com3.with_column(\"FINAL_AMOUNT\",\n# #                         F.when(F.col(\"VOYAGEBUCKET\") == 'Bucket 1',F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\"))\n# #                          .when(F.col(\"VOYAGEBUCKET\").in_('Bucket 3', 'Bucket 4', 'Bucket Charter'),\n# #                                F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\") + F.col(\"NONPERIODDISTRIBUTED_AMOUNT\"))\n# #                          .otherwise(F.lit(None)))\n\n\n\n# # # NON Charter and Non Common OU data treatment\n\n\n# # # 1. Define the window (the group)\n# # window_spec = Window.partition_by(\"SHIP_CD\", \"BUSINESS_UNIT_DESCRIPTION\", \"OPERATING_UNIT_DESCRIPTION\",\n# #                                     \"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\", \"VOYAGE_ID\", \"ACCOUNT\",\n# #                                     \"STRADDLE_FLAG\", \"VOYAGE_CD\").order_by(F.col(\"CONV_SAIL_DAT\"))\n\n# # master=master_file.with_column_renamed(\"SHIP_CD\" , \"SHIP_CD_1\")\n\n# # #2. Chain all operations together\n# # df_norm=df_norm.filter(F.col('SHIP_CD')!='Unknown')\n\n# # df_norm1 = df_norm.with_column(\"M0_M1\",F.when(F.col(\"ACCOUNT\") == '40013-Cruise Revenue Promo Packages', F.lit('NTR-CRpromo'))\n# #                                         .otherwise(F.col(\"M0_M1\")))\\\n# #                   .join(master,((df_norm[\"VOYAGE_ID\"] == master[\"MXP_VOYAGE_CD\"]) &\n# #                                 (df_norm[\"SHIP_CD\"] == master[\"SHIP_CD_1\"])),\"left\").distinct()\\\n# #                   .with_column(\"STRADDLE_OCCURRENCE\",F.row_number().over(window_spec))\\\n# #                   .with_column(\"VOYAGE_ID\",F.coalesce(F.col(\"VOYAGE_ID\"), F.lit(\"No Voyage Cd\")))\\\n# #                   .with_column(\"FISCAL_YEAR_NUMBER\",F.col(\"FISCAL_YEAR_NUMBER\").cast(T.FloatType()))\\\n# #                   .with_column(\"ACCOUNTING_PERIOD\",F.col(\"ACCOUNTING_PERIOD\").cast(T.FloatType()))\n                \n\n# # #  Define the conditions for the initial buckets ---\n\n# # condition_promo = (df_norm1['ACCOUNT'] == '40013-Cruise Revenue Promo Packages') & (df_norm1['VOYAGE_ID'] == 'No Voyage Cd')\n# # condition1 = (df_norm1['ACCOUNT'] == '40013-Cruise Revenue Promo Packages') & (df_norm1['VOYAGE_ID'] != 'No Voyage Cd')\n# # condition2 = (df_norm1['ACCOUNT'] != '40013-Cruise Revenue Promo Packages') & (df_norm1['VOYAGE_ID'] == 'No Voyage Cd')\n# # condition3 = (df_norm1['ACCOUNT'] != '40013-Cruise Revenue Promo Packages') & (df_norm1['STRADDLE_FLAG'] == 'Non-straddle') & (df_norm1['ACCOUNTING_PERIOD'] == df_norm1['CONV_SAIL_MONTH']) & (df_norm1['FISCAL_YEAR_NUMBER'] == df_norm1['CONV_SAIL_YEAR']) & (~df_norm1['BFS_CHARTER_CD'].isin(['SX']))\n# # condition4 = (df_norm1['ACCOUNT'] != '40013-Cruise Revenue Promo Packages') & (df_norm1['STRADDLE_FLAG'] == 'straddle') & (df_norm1['ACCOUNTING_PERIOD'] == df_norm1['CONV_SAIL_MONTH']) & (df_norm1['FISCAL_YEAR_NUMBER'] == df_norm1['CONV_SAIL_YEAR']) & (~df_norm1['BFS_CHARTER_CD'].isin(['SX']))\n# # condition_charter = (df_norm1['ACCOUNT'] != '40013-Cruise Revenue Promo Packages') & (df_norm1['BFS_CHARTER_CD'].isin(['SX']) | df_norm1['VOYAGE_ID'].startswith('SM') | df_norm1['VOYAGE_ID'].startswith('SX'))\n\n\n\n# # #Apply the initial bucketing\n# # dfnorm2 = df_norm1.with_column(\"VOYAGEBUCKET\",\n# #                                     F.when(condition_promo, 'Bucket Promo')\n# #                                      .when(condition1, 'Bucket 1')\n# #                                      .when(condition2, 'Bucket 2')\n# #                                      .when(condition3, 'Bucket 3')\n# #                                      .when(condition4, 'Bucket 4')\n# #                                      .when(condition_charter, 'Bucket Charter')\n# #                                      .otherwise('Bucket 5')) # Default to Bucket 5\n\n# # condition = ((F.col(\"FISCAL_YEAR_NUMBER\") != F.col(\"CONV_SAIL_YEAR\")) |\n# #              (F.col(\"ACCOUNTING_PERIOD\") != F.col(\"CONV_SAIL_MONTH\")) |\n# #              (F.col(\"CONV_SAIL_MONTH\").is_null() & (F.col(\"SHIP_CD\") != F.col(\"SHIP_CD_1\"))))\n\n# # dfnorm2 = dfnorm2.with_column(\"NEW_VOYAGE_ID\",F.when(condition, F.lit('Other voyages'))\n# #                                                .otherwise(F.col(\"VOYAGE_ID\"))).with_column(\"NEW_VOYAGE_ID\", F.col(\"NEW_VOYAGE_ID\").cast(T.StringType()))\n\n\n# # dfnorm2 = dfnorm2.with_column(\"JOURNAL_MONETARY_AMOUNT_ADJ\",F.when(F.col(\"STRADDLE_FLAG\") == \"straddle\",\n# #         F.when(\n# #             (F.col(\"MXP_VOYAGE_CD\").is_null()) | (F.col(\"MXP_VOYAGE_CD\") ==F.lit('0')),\n# #             F.when(F.col(\"VOYAGEBUCKET\").is_null(), F.lit(0))\n# #              .otherwise(F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\"))\n# #         )\n# #         .when(\n# #             F.col(\"SAIL_DAY_QTY\") > 0,\n# #             (F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\") / F.col(\"SAIL_DAY_QTY\")) * F.col(\"CONV_SAIL_DAY_QTY\")\n# #         )\n# #         .otherwise(F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\"))\n# #     ).otherwise(F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\"))\n# # )\n# # dfnorm2 = dfnorm2.with_column(\"GSS\", F.coalesce(F.col(\"GSS\"), F.lit(0)))\\\n# #     .with_column(\"PORTCD_ACTIVITY\", F.coalesce(F.col(\"PORTCD_ACTIVITY\"), F.lit('NA')))\\\n# #     .with_column(\"PRODUCT_CD\", F.coalesce(F.col(\"PRODUCT_CD\"), F.lit('NA')))\\\n# #     .with_column(\"PRODUCT_DESC\", F.coalesce(F.col(\"PRODUCT_DESC\"), F.lit('NA')))\\\n# #     .with_column(\"RM_ROLLUP_PRODUCT_CD\", F.coalesce(F.col(\"RM_ROLLUP_PRODUCT_CD\"), F.lit('NA')))\\\n# #     .with_column(\"RM_ROLLUP_PRODUCT_DESC\", F.coalesce(F.col(\"RM_ROLLUP_PRODUCT_DESC\"), F.lit('NA')))\n\n\n# # def distribute_amounts(bucket_name, distributed_col_name):\n    \n# #     # Define the main window (group) for all calculations ---\n# #     window_spec = Window.partition_by(\"SHIP_CD\", \"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\", \"BUSINESS_UNIT_DESCRIPTION\", \"OPERATING_UNIT_DESCRIPTION\")\n    \n# #     # 1. Calculate group-level metrics, one column at a time\n# #     group_calcs = dfnorm2.with_column('BUCKET_3_EXISTS', F.max(F.when(F.col('VOYAGEBUCKET') == 'Bucket 3', 1).otherwise(0)).over(window_spec))\\\n# #                          .with_column('BUCKET_4_EXISTS', F.max(F.when(F.col('VOYAGEBUCKET') == 'Bucket 4', 1).otherwise(0)).over(window_spec))\\\n# #                          .with_column('AMOUNT_TO_DISTRIBUTE', F.sum(F.when(F.col('VOYAGEBUCKET') == bucket_name, F.col('JOURNAL_MONETARY_AMOUNT_ADJ')).otherwise(0)).over(window_spec))\n\n# #     # 2. Determine which rows are \"eligible\" for allocation\n# #     eligible_rows = group_calcs.with_column(\n# #         'IS_ELIGIBLE',\n# #         F.when( (F.col('BUCKET_3_EXISTS') == 1) & (F.col('BUCKET_4_EXISTS') == 1), F.col('VOYAGEBUCKET').isin('Bucket 3', 'Bucket 4') )\n# #          .when( (F.col('BUCKET_3_EXISTS') == 1), F.col('VOYAGEBUCKET') == 'Bucket 3' )\n# #          .when( (F.col('BUCKET_4_EXISTS') == 1), F.col('VOYAGEBUCKET') == 'Bucket 4' )\n# #          .otherwise(F.col('VOYAGEBUCKET') == 'Bucket Charter')\n# #     )\n\n# #     # 3. Calculate the total 'Straddle Pax' for ONLY the eligible rows\n# #     pax_days_calcs = eligible_rows.with_column('TOTAL_ELIGIBLE_PAX_DAYS', F.sum(F.when(F.col('IS_ELIGIBLE'), F.col('STRADDLE_PAX')).otherwise(0)).over(window_spec))\n\n# #     # 4. Calculate the final distributed amount for each eligible row\n# #     final_calcs = pax_days_calcs.with_column( distributed_col_name, F.when(\n# #             (F.col('IS_ELIGIBLE')) & (F.col('TOTAL_ELIGIBLE_PAX_DAYS') > 0),\n# #             (F.col('STRADDLE_PAX') / F.col('TOTAL_ELIGIBLE_PAX_DAYS')) * F.col('AMOUNT_TO_DISTRIBUTE')\n# #         ).otherwise(0))\n    \n# #     # Return a DataFrame with only the original columns plus the new distributed amount\n# #     return final_calcs.filter(F.col('IS_ELIGIBLE')).select(dfnorm2.columns + [distributed_col_name])\n\n\n# # null_period_results = distribute_amounts( 'Bucket 2', 'NULLPERIODDISTRIBUTED_AMOUNT')\n# # non_period_results = distribute_amounts( 'Bucket 5', 'NONPERIODDISTRIBUTED_AMOUNT')\n\n# # null_cols=['FISCAL_YEAR_NUMBER','ACCOUNTING_PERIOD','BUSINESS_UNIT_DESCRIPTION','OPERATING_UNIT_DESCRIPTION','SHIP_CD','M0_M1','VOYAGE_ID','ACCOUNT','JOURNAL_MONETARY_AMOUNT_ADJ','VOYAGE_CD','MXP_VOYAGE_CD',\n# #     'VOY_GRAB','ALBS','LOAD_FACTOR','PAX_DAYS','DO_CAPS_DAYS','PORTCD_ACTIVITY','GSS','BFS_CHARTER_CD','SAIL_DAT','RETURN_DAT','SAIL_DAY_QTY','EMBARK_PORT_CD',\n# #     'DISEMBARK_PORT_CD','SAIL_STATUS_CD','PRODUCT_CD','PRODUCT_DESC','RM_ROLLUP_PRODUCT_CD','RM_ROLLUP_PRODUCT_DESC','MAIN_VOYAGE_CD','END_OF_MONTH','STRADDLE_FLAG',\n# #     'CONV_SAIL_DAT','CONV_RETURN_DAT','CONV_SAIL_DAY_QTY','CONV_SAIL_MONTH','CONV_SAIL_YEAR','STRADDLE_PAX_PD','STRADDLE_PAX',\n# #     'STRADDLE_OCCURRENCE','VOYAGEBUCKET','NEW_VOYAGE_ID']\n# # join_keys=['FISCAL_YEAR_NUMBER','ACCOUNTING_PERIOD','BUSINESS_UNIT_DESCRIPTION','OPERATING_UNIT_DESCRIPTION','SHIP_CD','M0_M1','VOYAGE_ID','ACCOUNT','VOYAGE_CD','MXP_VOYAGE_CD',\n# #     'VOY_GRAB','ALBS','LOAD_FACTOR','PAX_DAYS','DO_CAPS_DAYS','GSS','PORTCD_ACTIVITY','BFS_CHARTER_CD','SAIL_DAT','RETURN_DAT','SAIL_DAY_QTY','EMBARK_PORT_CD',\n# #     'DISEMBARK_PORT_CD','SAIL_STATUS_CD','PRODUCT_CD','PRODUCT_DESC','RM_ROLLUP_PRODUCT_CD','RM_ROLLUP_PRODUCT_DESC','END_OF_MONTH','STRADDLE_FLAG',\n# #     'CONV_SAIL_DAT','CONV_RETURN_DAT','CONV_SAIL_DAY_QTY','CONV_SAIL_MONTH','CONV_SAIL_YEAR','STRADDLE_PAX_PD','STRADDLE_PAX',\n# #     'STRADDLE_OCCURRENCE','VOYAGEBUCKET','NEW_VOYAGE_ID']\n\n# # # Select the necessary columns from each result set before joining\n# # null_to_join = null_period_results.select(null_cols + ['NULLPERIODDISTRIBUTED_AMOUNT'])\n# # non_to_join = non_period_results.select(join_keys + ['NONPERIODDISTRIBUTED_AMOUNT'])\n\n# # # Perform a full outer join to combine all rows from both results\n# # dfnorm3 = null_to_join.join(\n# #     non_to_join,\n# #     on=join_keys,\n# #     how='left'\n# # )\n\n\n# # dfnorm4 = dfnorm3.select(\"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\",\"BUSINESS_UNIT_DESCRIPTION\", \"OPERATING_UNIT_DESCRIPTION\",\n# #                         \"SHIP_CD\", \"M0_M1\", \"VOYAGE_ID\", \"ACCOUNT\", \"VOYAGE_CD\",\"MXP_VOYAGE_CD\", \"VOY_GRAB\", \"LOAD_FACTOR\", \"PAX_DAYS\", \"DO_CAPS_DAYS\",\n# #                         \"BFS_CHARTER_CD\", \"ALBS\", \"PORTCD_ACTIVITY\", \"GSS\", \"SAIL_DAT\",\"RETURN_DAT\", \"SAIL_DAY_QTY\", \"EMBARK_PORT_CD\", \"DISEMBARK_PORT_CD\",\n# #                         \"SAIL_STATUS_CD\", \"PRODUCT_CD\", \"PRODUCT_DESC\",\"RM_ROLLUP_PRODUCT_CD\", \"RM_ROLLUP_PRODUCT_DESC\", \"MAIN_VOYAGE_CD\",\n# #                         \"END_OF_MONTH\", \"STRADDLE_FLAG\", \"CONV_SAIL_DAT\",\"CONV_RETURN_DAT\", \"CONV_SAIL_DAY_QTY\", \"CONV_SAIL_MONTH\",\n# #                         \"CONV_SAIL_YEAR\", \"VOYAGEBUCKET\", \"NEW_VOYAGE_ID\",\"STRADDLE_OCCURRENCE\", \"NULLPERIODDISTRIBUTED_AMOUNT\",\"NONPERIODDISTRIBUTED_AMOUNT\")\n\n\n# # join_keys = [\"FISCAL_YEAR_NUMBER\", \"ACCOUNTING_PERIOD\",\n# #     \"BUSINESS_UNIT_DESCRIPTION\", \"OPERATING_UNIT_DESCRIPTION\",\n# #     \"SHIP_CD\", \"M0_M1\", \"VOYAGE_ID\", \"ACCOUNT\",\n# #     \"MXP_VOYAGE_CD\", \"VOY_GRAB\", \"LOAD_FACTOR\", \"PAX_DAYS\", \"DO_CAPS_DAYS\",\n# #     \"BFS_CHARTER_CD\", \"ALBS\", \"PORTCD_ACTIVITY\", \"GSS\", \"SAIL_DAT\",\n# #     \"RETURN_DAT\", \"SAIL_DAY_QTY\", \"EMBARK_PORT_CD\", \"DISEMBARK_PORT_CD\",\n# #     \"VOYAGE_CD\", \"SAIL_STATUS_CD\", \"PRODUCT_CD\", \"PRODUCT_DESC\",\n# #     \"RM_ROLLUP_PRODUCT_CD\", \"RM_ROLLUP_PRODUCT_DESC\", \"MAIN_VOYAGE_CD\",\n# #     \"END_OF_MONTH\", \"STRADDLE_FLAG\", \"CONV_SAIL_DAT\",\n# #     \"CONV_RETURN_DAT\", \"CONV_SAIL_DAY_QTY\", \"CONV_SAIL_MONTH\",\n# #     \"CONV_SAIL_YEAR\", \"STRADDLE_OCCURRENCE\", \"VOYAGEBUCKET\", \"NEW_VOYAGE_ID\"]\n\n# # dfnorm5 = dfnorm2.join(dfnorm4, join_keys, \"left\")\n\n# # dfnorm5 = dfnorm5.with_column(\"NONPERIODDISTRIBUTED_AMOUNT\", F.coalesce(F.col(\"NONPERIODDISTRIBUTED_AMOUNT\"), F.lit(0)))\\\n# #                  .with_column(\"NULLPERIODDISTRIBUTED_AMOUNT\", F.coalesce(F.col(\"NULLPERIODDISTRIBUTED_AMOUNT\"), F.lit(0)))\\\n# #                  .with_column(\"JOURNAL_MONETARY_AMOUNT_ADJ\", F.coalesce(F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\"), F.lit(0)))\n\n\n\n# # dfnorm5 = dfnorm5.with_column(\"FINAL_AMOUNT\",\n# #                             F.when(\n# #                                 F.col(\"VOYAGEBUCKET\").isin([\"Bucket 1\", \"Bucket Promo\"]),\n# #                                 F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\")\n# #                             ).when(\n# #                                 F.col(\"VOYAGEBUCKET\").isin([\"Bucket 3\", \"Bucket 4\", \"Bucket Charter\"]),\n# #                                 F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\") + F.col(\"NONPERIODDISTRIBUTED_AMOUNT\") + F.col(\"NULLPERIODDISTRIBUTED_AMOUNT\")\n# #                             ).otherwise(F.lit(None))\n# #                         ).drop('SHIP_CD_1')\n\n\n# # dfnorm5_processed = dfnorm5.with_column('CAPS_PER_DAY', F.col('DO_CAPS_DAYS') / F.col('SAIL_DAY_QTY'))\\\n# #                             .with_column('PAX_PER_DAY', F.col('PAX_DAYS') / F.col('SAIL_DAY_QTY'))\\\n# #                             .with_column('PRTD_CAPS_DAYS', F.col('CAPS_PER_DAY') * F.col('CONV_SAIL_DAY_QTY'))\\\n# #                             .with_column('PRTD_PAX_DAYS', F.col('PAX_PER_DAY') * F.col('CONV_SAIL_DAY_QTY'))\\\n# #                             .with_column('PCD',  F.col('FINAL_AMOUNT') / F.col('PRTD_CAPS_DAYS'))\\\n# #                             .with_column('PPD',  F.col('FINAL_AMOUNT') / F.col('PRTD_PAX_DAYS'))\\\n# #                             .with_columns(\n# #                             # Add columns to match schema for future union\n# #                             ['AMOUNT_TO_DISTRIBUTE', 'TOTALPAXDAYS', 'PAXPERCENT'],\n# #                             [F.lit(0), F.lit(0), F.lit(0)]\n# #                         )\n\n# # df_comv1_processed = df_com1.with_column_renamed('TOTAL_PAX_DAYS', 'TOTALPAXDAYS') \\\n# #                              .with_column_renamed('PAX_WEIGHTAGE', 'PAXPERCENT')\n\n# # # Add and calculate new columns to align with dfnorm5 schema\n# # df_comv1_processed = df_comv1_processed.with_columns(\n# #     [   'NEW_VOYAGE_ID', 'AMOUNT_TO_DISTRIBUTE', 'CAPS_PER_DAY', 'PRTD_CAPS_DAYS',\n# #         'PCD', 'PAX_PER_DAY', 'PRTD_PAX_DAYS', 'PPD', 'NONPERIODDISTRIBUTED_AMOUNT',\n# #         'NULLPERIODDISTRIBUTED_AMOUNT', 'STRADDLE_PAX', 'STRADDLE_PAX_PD'\n# #     ],\n# #     [   F.lit('0'), F.lit(0), F.lit(0), F.lit(0), F.lit(0), F.lit(0), F.lit(0),\n# #         F.lit(0), F.lit(0), F.lit(0), F.lit(0), F.lit(0)\n# #     ]).with_column('FINAL_AMOUNT', F.col('JOURNAL_MONETARY_AMOUNT_ADJ'))\\\n# #       .with_column('VOYAGEBUCKET', F.lit('Common -OU'))\n\n\n# # final_cols_med = sorted(list(set(dfnorm5_processed.columns) | set(df_comv1_processed.columns)))\n# # df_med = df_comv1_processed.select(final_cols_med).union_all(dfnorm5_processed.select(final_cols_med))\n\n# # df_med = df_med.with_columns(['SIXTHMAN_VOYAGE', 'TRADITIONAL_VOYAGE_ID'],[F.lit('NA'), F.lit('NA')])\n\n# # df_charter2_processed = df_charter2.with_column_renamed('TOTAL_PAX_DAYS', 'TOTALPAXDAYS') \\\n# #                                    .with_column_renamed('PAX_WEIGHTAGE', 'PAXPERCENT')\\\n# #                                    .with_column('VOYAGEBUCKET', F.lit('Bucket Charter'))\n\n# # # Add and calculate columns to align with df_med schema\n# # df_charter2_processed = df_charter2_processed.with_columns(\n# #     [   'VOYAGEBUCKET', 'STRADDLE_OCCURRENCE', 'NEW_VOYAGE_ID', 'AMOUNT_TO_DISTRIBUTE',\n# #         'CAPS_PER_DAY', 'PRTD_CAPS_DAYS', 'PCD', 'PAX_PER_DAY', 'PRTD_PAX_DAYS', 'PPD',\n# #         'STRADDLE_PAX', 'STRADDLE_PAX_PD', 'NULLPERIODDISTRIBUTED_AMOUNT', 'NONPERIODDISTRIBUTED_AMOUNT'\n# #     ],\n# #     [   F.lit('Bucket Charter'), F.lit(0), F.lit('NA'), F.lit(0), F.lit(0), F.lit(0),\n# #         F.lit(0), F.lit(0), F.lit(0), F.lit(0), F.lit(0), F.lit(0), F.lit(0), F.lit(0)\n# #     ]).with_column('FINAL_AMOUNT', F.col('JOURNAL_MONETARY_AMOUNT_ADJ'))\n\n\n# # final_cols_all = sorted(list(set(df_med.columns) | set(df_charter2_processed.columns)))\n# # df_med1 = df_med.select(final_cols_all).union_all(df_charter2_processed.select(final_cols_all))\n\n\n# # df_final = df_med1.select('FISCAL_YEAR_NUMBER','ACCOUNTING_PERIOD','BUSINESS_UNIT_DESCRIPTION','OPERATING_UNIT_DESCRIPTION','SHIP_CD','M0_M1',\n# #                                     'VOYAGE_ID','ACCOUNT','JOURNAL_MONETARY_AMOUNT_ADJ','VOYAGE_CD','MXP_VOYAGE_CD','VOY_GRAB','ALBS','LOAD_FACTOR','PAX_DAYS',\n# #                                     'DO_CAPS_DAYS','PORTCD_ACTIVITY','GSS','SAIL_DAT','RETURN_DAT','SAIL_DAY_QTY','EMBARK_PORT_CD','DISEMBARK_PORT_CD','BFS_CHARTER_CD',\n# #                                     'RM_ROLLUP_PRODUCT_DESC','MAIN_VOYAGE_CD','END_OF_MONTH','STRADDLE_FLAG','CONV_SAIL_DAT','CONV_RETURN_DAT','CONV_SAIL_DAY_QTY',\n# #                                     'CONV_SAIL_MONTH','CONV_SAIL_YEAR','STRADDLE_OCCURRENCE','VOYAGEBUCKET','NEW_VOYAGE_ID','AMOUNT_TO_DISTRIBUTE','TOTALPAXDAYS','PAXPERCENT',\n# #                                     'FINAL_AMOUNT','CAPS_PER_DAY','PRTD_CAPS_DAYS','PCD','PAX_PER_DAY','PRTD_PAX_DAYS','PPD','SAIL_STATUS_CD','PRODUCT_CD','RM_ROLLUP_PRODUCT_CD',\n# #                                     'SIXTHMAN_VOYAGE','TRADITIONAL_VOYAGE_ID','SHIP_NAME','SHIP_CLASS')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad2227e9-71f6-4e0c-96c0-2cba29b40f98",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df_with_count.count()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a8962051-3a7d-49ea-a5f7-330436940243",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df_with_voyage_merged.agg(F.sum(\"JOURNAL_MONETARY_AMOUNT_ADJ\"))\n\n# df_charter_map.group_by(\"mxp_voyage_cd\").count()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5369968c-e31c-4f71-855f-214cda0290e5",
   "metadata": {
    "language": "python",
    "name": "Appending_Code",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# 1. Load Data (Assume data is already in Snowflake stages/tables)\nproduct_map = session.table(\"L00_STG.NCLH_PRODUCT_MAPPING\").with_column_renamed(\"PRODUCT_DESC\", \"PRODUCT_DESCRIPTION\") \\\n\n# 2. Schema Cleaning & Hierarchy Join\ndf = df_final.with_column(\"ACCOUNT_NUMBER\", F.substring(F.col(\"ACCOUNT\"), 1, 5))\n\n# standard left join replacing SQLDF\ndf = df.join(mapping, \"ACCOUNT_NUMBER\", \"left\") \n\n# 3. Dynamic Voyage Logic (replacing np.where and manual apply)\n# Logical conditions based on fiscal attributes\nvoyage_cond = (\n    (F.col(\"FISCAL_YEAR_NUMBER\") != F.col(\"CONV_SAIL_YEAR\")) | \n    (F.col(\"ACCOUNTING_PERIOD\") != F.col(\"CONV_SAIL_MONTH\")) | \n    F.col(\"CONV_SAIL_MONTH\").is_null())\n\n\nfiscal_match_val = F.concat(\n    F.substring(F.col(\"FISCAL_YEAR_NUMBER\").cast('string'), 3, 2),  # Get last two digits of the year (e.g., '25' from 2025)\n    F.lpad(F.col(\"ACCOUNTING_PERIOD\").cast('string'), 2, F.lit('0'))) # Pad period with '0' (e.g., '08' from 8)\n\n\ndf = df.with_columns(\n    [\"NEW_VOYAGE_ID\", \"SUB_STRING\"],\n    [\n        F.when(voyage_cond, F.lit(\"Other voyages\")).otherwise(F.col(\"VOYAGE_ID\")),\n        F.substring(F.col(\"VOYAGE_ID\"), 4, 4)\n    ])\n\n# Refine ID based on custom check logic\ndf = df.with_column(\"NEW_VOYAGE_ID\", \n                    F.when(F.col(\"SUB_STRING\") == fiscal_match_val, F.col(\"VOYAGE_ID\"))\n                    .otherwise(F.lit(\"Other Voyage Code\")))\n\n# 6. Fuel Placeholder Metrics\nfuel_metrics = ['HFO$','HFOMT','MGO$','MGOMT','BIO$','BIOMT','HFO$/MT','MGO$/MT','BIO$/MT','MGO_TOTAL_MT','HFO_TOTAL_MT','BIO_TOTAL_MT','MGO_TOTAL_MT/SAIL_DAY_QTY',\n                'HFO_TOTAL_MT/SAIL_DAY_QTY','BIO_TOTAL_MT/SAIL_DAY_QTY','MGO_CONSUMPTION','HFO_CONSUMPTION','BIO_CONSUMPTION','MGO_MTCOST','HFO_MTCOST','BIO_MTCOST']\nfor metric in fuel_metrics:\n    df = df.with_column(metric, F.lit(0))\n\ndf=df.select('FISCAL_YEAR_NUMBER','ACCOUNTING_PERIOD','SHIP_CD','M0_M1','VOYAGE_ID','ACCOUNT','LEVEL_1','LEVEL_2','LEVEL_3','LEVEL_4',\n            'VOYAGE_CD','MXP_VOYAGE_CD','VOY_GRAB','ALBS','LOAD_FACTOR','PAX_DAYS','DO_CAPS_DAYS','PORTCD_ACTIVITY','GSS',\n            'SAIL_DAT','RETURN_DAT','SAIL_DAY_QTY','EMBARK_PORT_CD','DISEMBARK_PORT_CD','SAIL_STATUS_CD','PRODUCT_CD',\n            'RM_ROLLUP_PRODUCT_CD','RM_ROLLUP_PRODUCT_DESC','MAIN_VOYAGE_CD','END_OF_MONTH','STRADDLE_FLAG',\n            'CONV_SAIL_DAT','CONV_RETURN_DAT','CONV_SAIL_DAY_QTY','CONV_SAIL_MONTH','CONV_SAIL_YEAR','CAPS_PER_DAY',\n            'PRTD_CAPS_DAYS','PAX_PER_DAY','PRTD_PAX_DAYS','VOYAGEBUCKET','JOURNAL_MONETARY_AMOUNT_ADJ','FINAL_AMOUNT',\n            'HFO$','HFOMT','MGO$','MGOMT','BIO$','BIOMT','HFO$/MT','MGO$/MT','BIO$/MT','MGO_TOTAL_MT','HFO_TOTAL_MT','BIO_TOTAL_MT','MGO_TOTAL_MT/SAIL_DAY_QTY',\n            'HFO_TOTAL_MT/SAIL_DAY_QTY','BIO_TOTAL_MT/SAIL_DAY_QTY','MGO_CONSUMPTION','HFO_CONSUMPTION','BIO_CONSUMPTION','MGO_MTCOST','HFO_MTCOST','BIO_MTCOST',\n            'SUB_STRING','NEW_VOYAGE_ID','PCD','PPD','STRADDLE_OCCURRENCE','BUSINESS_UNIT_DESCRIPTION','OPERATING_UNIT_DESCRIPTION',\n            'SIXTHMAN_VOYAGE','TRADITIONAL_VOYAGE_ID','BFS_CHARTER_CD','SHIP_NAME','SHIP_CLASS')\n\n\n# 7. Final Product Join and Materialization\ndf = df.join(product_map, [\"VOYAGE_CD\", \"RM_ROLLUP_PRODUCT_DESC\"], \"left\")\n\ndf = df.with_column('ADJUSTED_FINAL_AMOUNT_NEW', F.col('JOURNAL_MONETARY_AMOUNT_ADJ')) \\\n       .with_column('ADJUSTED_FINAL_AMOUNT', F.col('JOURNAL_MONETARY_AMOUNT_ADJ')) \\\n       .with_column(\"FIN_AMT_PCD\", F.round(F.when(F.col(\"PRTD_CAPS_DAYS\") != 0, \n                         F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\") / F.col(\"PRTD_CAPS_DAYS\")).otherwise(0), 4))\\\n       .with_column(\"FIN_AMT_PPD\", F.round(F.when(F.col(\"PRTD_PAX_DAYS\") != 0, \n                         F.col(\"JOURNAL_MONETARY_AMOUNT_ADJ\") / F.col(\"PRTD_PAX_DAYS\")).otherwise(0), 4))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f2fcabb-d4f9-4ba1-b25e-ed32ab2ff371",
   "metadata": {
    "language": "python",
    "name": "Meta_data_Creation",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\n# Add metadata columns\ndf = df.with_column(\"MD5_HUB_VOYAGE\", F.md5(F.col(\"VOYAGE_ID\")))\ncolumns_to_hash = [c for c in df.columns if c not in (\"VOYAGE_ID\", \"LDTS\", \"RCSR\", \"LAST_MODIFIED_BY\", \"MD5_HUB_VOYAGE\")]\ndf = df.withColumn(\"HASH_DIFF\", F.md5(F.concat(*[F.coalesce(F.col(c).cast(\"string\"), F.lit(\"\")).cast(\"string\") for c in columns_to_hash])))\nFinal_NTR_Output = df.withColumn(\"LDTS\", F.current_timestamp()) \\\n                   .withColumn(\"RCSR\", F.lit('Master_data,NTR_PSFT')) \\\n                   .withColumn(\"LAST_MODIFIED_BY\", F.current_user())\n\n\n# # Materialize result in Snowflake (triggers actual execution)\nFinal_NTR_Output.write.mode(\"overwrite\").save_as_table(\"L00_STG.SAT_VFM_NCL_M0_NTR\")\n\n\n# Final_NTR_Output.write.mode(\"overwrite\").save_as_table(\"VESSOPS_D.L20_BDV.SAT_VFM_NCL_M0_NTR\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23b7ab53-5e50-4300-8d73-3abbb182c9bb",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df_com1.write.mode(\"overwrite\").save_as_table(\"VESSOPS_D.L00_STG.VFM_NCL_M0_NTR_TEST\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6ae445fe-9069-4e7d-93ad-8757f8ddd4e6",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}